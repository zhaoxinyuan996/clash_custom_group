import re
import yaml
from collections import defaultdict
from typing import Optional
import requests
import http.server
import socketserver
from urllib.parse import unquote

PORT = 8000

delay_url = 'http://www.gstatic.com/generate_204'
delay_interval = 100


# é‡å†™ç»„
def handler(lis: list) -> list:
    groups = defaultdict(list)
    lis.sort(key=lambda i: i['name'])
    for i in lis:
        name = i['name']
        if re.search(r'(hongkong|kong kong|é¦™æ¸¯)', name.lower()):
            groups['é¦™æ¸¯è´Ÿè½½ç»„'].append(name)

        elif re.search(r'(taiwan|tai wan|å°æ¹¾)', name.lower()):
            groups['å°æ¹¾è´Ÿè½½ç»„'].append(name)

        elif re.search(r'(japan|jp|æ—¥æœ¬)', name.lower()):
            groups['æ—¥æœ¬è´Ÿè½½ç»„'].append(name)
        else:
            groups['å…¶ä»–'].append(name)

    proxy_groups = [
        {
            'name': 'ðŸš€ èŠ‚ç‚¹é€‰æ‹©',
            'type': 'select',
            'proxies': ['é¦™æ¸¯è´Ÿè½½ç»„', 'å°æ¹¾è´Ÿè½½ç»„', 'æ—¥æœ¬è´Ÿè½½ç»„', 'å…¶ä»–']
         },
        {
            'name': 'é¦™æ¸¯è´Ÿè½½ç»„',
            'type': 'load-balance',
            'url': delay_url,
            'interval': delay_interval,
            'proxies': groups['é¦™æ¸¯è´Ÿè½½ç»„']
        },
        {
            'name': 'å°æ¹¾è´Ÿè½½ç»„',
            'type': 'load-balance',
            'url': delay_url,
            'interval': delay_interval,
            'proxies': groups['å°æ¹¾è´Ÿè½½ç»„']
        },
        {
            'name': 'æ—¥æœ¬è´Ÿè½½ç»„',
            'type': 'load-balance',
            'url': delay_url,
            'interval': delay_interval,
            'proxies': groups['æ—¥æœ¬è´Ÿè½½ç»„']
        },
        {
            'name': 'å…¶ä»–',
            'type': 'load-balance',
            'url': delay_url,
            'interval': delay_interval,
            'proxies': groups['å…¶ä»–']
        },
    ]
    return proxy_groups


class Handler(http.server.BaseHTTPRequestHandler):
    def _net(self):
        """æ·»åŠ å‰©ä½™æµé‡ç­‰ä¿¡æ¯"""
        path = unquote(self.path)
        print(f'parse: {self.path}')
        session = requests.Session()
        session.trust_env = False
        response = session.get(path)

        return response

    def parse_url(self) -> Optional[bytes]:
        if self.path and len(self.path) > 1:
            self.path = self.path[1:]
            return b''
        return b'parse url error'

    def get_clash(self, conf) -> Optional[bytes]:

        try:
            # conf = self._net().text
            print(conf[:100] if len(conf) > 100 else conf)

            conf = yaml.safe_load(conf)
            groups_agent = handler(conf['proxies'])
            groups_agent.extend(conf['proxy-groups'][1:])
            conf['proxy-groups'] = groups_agent

            res = yaml.safe_dump(conf, allow_unicode=True, sort_keys=False).encode()
            self.end_headers()
            return res
        except Exception as e:
            print(e)
            return str(e).encode()

    def end_headers(self):
        ...

    def do_GET(self):
        self.parse_url()
        headers = b'HTTP/1.1 200 OK\r\n'
        response = self._net()
        for k, v in response.headers.items():
            if k.lower() in ('content-encoding', 'content-length', 'transfer-encoding'):
                continue
            headers += f'{k}: {v}\r\n'.encode()
        response = self.get_clash(response.content)
        headers += f'Content-Length: {len(response)}\r\n'.encode()
        headers += b'\r\n'

        # print(headers.decode())
        self.wfile.write(headers + response)

    def handle(self):
        self.handle_one_request()


if __name__ == '__main__':
    with socketserver.TCPServer(("", PORT), Handler) as httpd:
        print("serving at port", PORT)
        httpd.serve_forever()
